{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "import IPython\n",
    "import random\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "def isNAN(num):\n",
    "    return num != num\n",
    "import rdkit\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import Descriptors\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "K = tf.keras.backend\n",
    "import datetime\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "from tqdm import tqdm\n",
    "import rdkit\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import rdMolDescriptors\n",
    "from rdkit.Chem import Draw\n",
    "from rdkit.Chem.Draw import IPythonConsole\n",
    "from rdkit.Chem import Descriptors\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit import DataStructs\n",
    "from math import sqrt\n",
    "from rdkit.Chem.Draw import SimilarityMaps\n",
    "import kerastuner as kt\n",
    "\n",
    "def cosine_mat(x,y):\n",
    "    '''x, y are same shape array'''\n",
    "    if np.sum(x**2) == 0 or np.sum(y**2) == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return (np.sum(x*y)/(sqrt(np.sum(x**2))*sqrt(np.sum(y**2))))\n",
    "def isNaN(num):\n",
    "    return num != num\n",
    "import pickle\n",
    "\n",
    "with open('Ontology/012921/char2idx_class_V1.pkl','rb') as f:\n",
    "    class_  = pickle.load(f)\n",
    "with open('Ontology/012921/char2idx_super_V1.pkl','rb') as f:\n",
    "    superclass_  = pickle.load(f)\n",
    "with open('Ontology/012921/char2idx_path_V1.pkl','rb') as f:\n",
    "    pathway_  = pickle.load(f)\n",
    "\n",
    "with open('ontology/012921/datset_class_all_V1.pkl','rb') as r:\n",
    "    dataset = pickle.load(r)\n",
    "\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "def FP(smiles,radi):\n",
    "    binary = np.zeros((2048*(radi)), int)\n",
    "    formula = np.zeros((2048),int)\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    mol = Chem.AddHs(mol)\n",
    "    mol_bi = {}\n",
    "    for r in range(radi+1):\n",
    "        mol_fp = rdMolDescriptors.GetMorganFingerprintAsBitVect(mol, radius=r, bitInfo=mol_bi, nBits = 2048)\n",
    "        mol_bi_QC = []\n",
    "        for i in mol_fp.GetOnBits():\n",
    "            idx = mol_bi[i][0][0]\n",
    "            radius_list = []\n",
    "            num_ = len(mol_bi[i])\n",
    "            for j in range(num_):\n",
    "                if mol_bi[i][j][1] == r:\n",
    "                    mol_bi_QC.append(i)\n",
    "                    break\n",
    "\n",
    "       \n",
    "        if r == 0:\n",
    "            for i in mol_bi_QC:\n",
    "                formula[i] = len([k for k in mol_bi[i] if k[1]==0])\n",
    "        else:\n",
    "            for i in mol_bi_QC:\n",
    "                binary[(2048*(r-1))+i] = len([k for k in mol_bi[i] if k[1]==r])\n",
    "    \n",
    "    \n",
    "    \n",
    "    return formula.reshape(1,2048),binary.reshape(1,4096)\n",
    "\n",
    "\n",
    "\n",
    "def dataset_generation(idx):\n",
    "    X_train_f = np.zeros((len(idx),2048),int)\n",
    "    X_train_b = np.zeros((len(idx),4096),int)\n",
    "    Y_train_path = np.zeros((len(idx),len(pathway_)),int)\n",
    "    Y_train_super = np.zeros((len(idx),len(superclass_)),int)\n",
    "    Y_train_class = np.zeros((len(idx),len(class_)),int)\n",
    "    for i,n in enumerate(idx):\n",
    "        smiles = dataset[n]['SMILES']\n",
    "        X_train_f[i] = FP(smiles,2)[0]\n",
    "        X_train_b[i] = FP(smiles,2)[1]\n",
    "        #Y_train_path[i] = dataset[n]['Pathway']\n",
    "        #Y_train_super[i] = dataset[n]['Super_class']\n",
    "        Y_train_class[i] = dataset[n]['Class']\n",
    "        \n",
    "    return [X_train_f,X_train_b], Y_train_class\n",
    "\n",
    "def model_build_DO(hp):\n",
    "    hp_unit1 = hp.Int('unit1', min_value = 3072, max_value = 6144, step = 1536) #3\n",
    "    hp_unit2 = hp.Int('unit2', min_value = 1536, max_value = 3072, step = 768) #3\n",
    "    hp_unit3 = hp.Int('unit3', min_value = 768, max_value = 1536, step = 384) #3\n",
    "    hp_drop = hp.Int('unit4', min_value = 1, max_value = 3, step = 1)/10 #3\n",
    "    hp_learning_rate = hp.Choice('learning_rate', values = [1e-2, 1e-3, 1e-4, 1e-5, 1e-6])\n",
    "    hp_l2_rate = hp.Choice('regularizer', values = [1e-1, 1e-2, 1e-3, 1e-4])\n",
    "    \n",
    "    l2 = keras.regularizers.l2(hp_l2_rate)\n",
    "    \n",
    "    \n",
    "    input_f = layers.Input(shape=(2048,))\n",
    "    input_b = layers.Input(shape=(4096,))\n",
    "    input_fp = layers.Concatenate()([input_f,input_b])\n",
    "    \n",
    "    X = layers.Dense(6144, activation = 'relu', kernel_regularizer=l2)(input_fp)\n",
    "    X = layers.BatchNormalization()(X)\n",
    "    X = layers.Dense(hp_unit1, activation = 'relu', kernel_regularizer=l2)(X)\n",
    "    X = layers.BatchNormalization()(X)\n",
    "    X = layers.Dense(hp_unit2, activation = 'relu', kernel_regularizer=l2)(X)\n",
    "    X = layers.BatchNormalization()(X)\n",
    "    X = layers.Dense(hp_unit3, activation = 'relu', kernel_regularizer=l2)(X)\n",
    "    X = layers.Dropout(hp_drop)(X)\n",
    "    output = layers.Dense(len(class_), activation = 'sigmoid')(X)\n",
    "    model = keras.Model(inputs = [input_f,input_b], outputs = output)\n",
    "    model.compile(optimizer=keras.optimizers.Adam(lr=hp_learning_rate, decay=1e-6),loss=['binary_crossentropy'],metrics=['cosine_proximity',top_k_categorical_accuracy])\n",
    "    return model  \n",
    "\n",
    "\n",
    "def top_k_categorical_accuracy(y_true, y_pred):\n",
    "    return tf.keras.metrics.top_k_categorical_accuracy(y_true, y_pred, k=2)\n",
    "\n",
    "\n",
    "class ClearTrainingOutput(tf.keras.callbacks.Callback):\n",
    "    def on_train_end(*args, **kwargs):\n",
    "        IPython.display.clear_output(wait = True)\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "b_key = list(dataset.keys())\n",
    "np.random.shuffle(b_key)\n",
    "dict_ = np.array(b_key)\n",
    "Y_ = np.array([ np.max(np.where(dataset[i]['Class']==1)[0]) for i in dict_])\n",
    "\n",
    "train_D, test_dict, y_train, y_test = train_test_split(dict_, Y_, test_size=0.2, random_state=1, stratify = Y_)\n",
    "train_dict, val_dict, y_train, y_val = train_test_split(train_D, y_train, test_size=0.2, random_state=1, stratify = y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, Y_train = dataset_generation(train_dict)\n",
    "X_val, Y_val = dataset_generation(val_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = kt.Hyperband(model_build_DO,\n",
    "                     objective = 'val_loss', \n",
    "                     max_epochs = 200,\n",
    "                     factor = 3,\n",
    "                     directory = 'my_dir2',\n",
    "                     project_name = 'npc_class')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner.search(x=X_train, y=Y_train,batch_size=128, epochs=200, validation_data=(X_val,Y_val), callbacks=[ClearTrainingOutput()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
